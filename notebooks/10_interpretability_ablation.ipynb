{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "emb = pd.read_parquet(\"../data/features/finbert_day_embeddings.parquet\").copy()\n",
    "emb[\"trading_date\"] = pd.to_datetime(emb[\"trading_date\"])\n",
    "emb = emb.sort_values(\"trading_date\")\n",
    "\n",
    "emb[\"ret_t\"] = emb[\"return_t_plus_1\"].shift(1)\n",
    "emb[\"vol_5\"] = emb[\"ret_t\"].rolling(5).std()\n",
    "emb[\"mom_5\"] = emb[\"ret_t\"].rolling(5).mean()\n",
    "emb = emb.dropna().copy()\n",
    "\n",
    "embedding_cols = [c for c in emb.columns if isinstance(c, (int, np.integer)) or str(c).isdigit()]\n",
    "if len(embedding_cols) == 0:\n",
    "    embedding_cols = [c for c in emb.columns if c not in [\"trading_date\",\"label\",\"return_t_plus_1\",\"ret_t\",\"vol_5\",\"mom_5\"]]\n",
    "\n",
    "market_cols = [\"ret_t\", \"vol_5\", \"mom_5\"]\n",
    "\n",
    "# Simple holdout: last ~20% of dates as test (still time-respecting)\n",
    "cutoff = emb[\"trading_date\"].quantile(0.8)\n",
    "\n",
    "train_df = emb[emb[\"trading_date\"] < cutoff].copy()\n",
    "test_df  = emb[emb[\"trading_date\"] >= cutoff].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "\n",
    "X_train_emb = train_df[embedding_cols].values\n",
    "X_test_emb  = test_df[embedding_cols].values\n",
    "X_train_mkt = scaler.fit_transform(train_df[market_cols].values)\n",
    "X_test_mkt  = scaler.transform(test_df[market_cols].values)\n",
    "\n",
    "X_train = np.hstack([X_train_emb, X_train_mkt])\n",
    "X_test  = np.hstack([X_test_emb, X_test_mkt])\n",
    "\n",
    "y_train = train_df[\"label\"].values\n",
    "y_test  = test_df[\"label\"].values\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Trained final model for interpretability demo.\")\n",
    "\n",
    "# For linear models, SHAP LinearExplainer is appropriate.\n",
    "explainer = shap.LinearExplainer(clf, X_train, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Build feature names: embedding dims + market features\n",
    "feature_names = [f\"emb_{i}\" for i in range(X_train_emb.shape[1])] + market_cols\n",
    "\n",
    "# Summarize global importance (mean absolute SHAP)\n",
    "mean_abs = np.mean(np.abs(shap_values), axis=0)\n",
    "imp = pd.DataFrame({\"feature\": feature_names, \"mean_abs_shap\": mean_abs})\n",
    "imp = imp.sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "imp.head(20)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_eval(Xtr, ytr, Xte, yte):\n",
    "    m = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "    m.fit(Xtr, ytr)\n",
    "    p = m.predict_proba(Xte)[:, 1]\n",
    "    return roc_auc_score(yte, p)\n",
    "\n",
    "# Build three variants:\n",
    "# 1) Embeddings only\n",
    "auc_emb = fit_eval(X_train_emb, y_train, X_test_emb, y_test)\n",
    "\n",
    "# 2) Market only\n",
    "auc_mkt = fit_eval(X_train_mkt, y_train, X_test_mkt, y_test)\n",
    "\n",
    "# 3) Fused\n",
    "auc_fused = fit_eval(X_train, y_train, X_test, y_test)\n",
    "\n",
    "abl = pd.DataFrame([\n",
    "    {\"model\": \"FinBERT embeddings only\", \"auc\": auc_emb},\n",
    "    {\"model\": \"Market features only\", \"auc\": auc_mkt},\n",
    "    {\"model\": \"Fused (FinBERT + market)\", \"auc\": auc_fused},\n",
    "]).sort_values(\"auc\", ascending=False)\n",
    "\n",
    "abl\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
